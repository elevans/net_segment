import os
import numpy as np
import scyjava as sj
import net_segment.util as util
import net_segment.roi as roi
import net_segment.networks as networks
import xarray as xr
import torch
from matplotlib import pyplot as plt
from collections import OrderedDict

def construct_resnet101(model_name: str, evaluation_mode=True):
    """
    Construct a ResNet network.
    """
    net = networks.deeplab2.resnet101(n_classes=1, nInputChannels=4, classifier='psp')
    state_dict_chkpnt = torch.load(os.path.join('models/', model_name + '.pth'), map_location=lambda storage, loc: storage)

    # remove the `module.` prefix from the model -- if trained using DataParallel
    if 'module.' in list(state_dict_chkpnt.keys())[0]:
        new_state_dict = OrderedDict()
        for k, v in state_dict_chkpnt.items():
            name = k[7:]  # remove `module.` from multi-gpu training
            new_state_dict[name] = v
    else:
        new_state_dict = state_dict_chkpnt

    net.load_state_dict(new_state_dict)

    if evaluation_mode:
        net.eval()

    return net


def results_to_dataset(results, ij_instance, show=False):
    """
    Send result mask from DEXTR to PyImageJ.
    :param result mask: result_mask from DEXTR
    :param ij_instance: Instance of ImageJ via PyImageJ
    :param show: Show result mask in ImageJ
    :return: net.imagej.DefaultDataset
    """
    results_ds = [] # return a list of Datasets if given list of numpy arrays
    if type(results) == list:
        for result in results:
            result_int = result.astype(int)
            result_ds = ij_instance.py.to_dataset(result_int)
            results_ds.append(results_ds)
            if show:
                ij_instance.ui().show('result mask', result_ds)
        
        return results_ds

    result_int = results.astype(int)
    result_ds = ij_instance.py.to_dataset(result_int)
    if show:
        ij_instance.ui().show('result mask', result_ds)
        
    return result_ds
    

def preds_to_dataset(predictions, ij_instance, show=False):
    """
    Send prediction from DEXTR to PyImagej.
    :param prediction: Predicition from DEXTR
    :param ij_instance: Instance of ImageJ via PyImageJ
    :param show: Show prediction in ImageJ
    :return: net.imagej.DefaultDataset
    """
    predictions_ds = [] # return a list of Datasets if given list of numpy arrays
    if type(predictions) == list:
        for prediction in predictions:
            prediction_ds = ij_instance.py.to_dataset(prediction)
            predictions_ds.append(prediction_ds)
            if show:
                ij_instance.ui().show('prediction', prediction_ds)
                ij_instance.py.run_macro("""run("Fire");""")

        return predictions_ds

    prediction_ds = ij_instance.py.to_dataset(predictions)
    if show:
        ij_instance.ui().show('prediction', prediction_ds)
        ij_instance.py.run_macro("""run("Fire");""")

    return prediction_ds


def create_extreme_point_window(image, ij_instance, title=None, axis='off'):
    """
    Generate window to collect extreme points around the object
    of interest.
    :param dataset: ImageJ dataset
    :param ij_instance: Instance of ImageJ via PyImageJ
    :param title: Title of image
    :param axis: Display axis on/off
    """
    # check image type
    if sj.isjava(image):
        display_image = util.java_to_numpy(image, ij_instance)
        
    # display image and collect points
    plt.ion()
    plt.axis(axis)
    plt.imshow(display_image, interpolation='nearest')
    plt.title(title)

    return

def create_extreme_point_heatmap(image: np.ndarray, resolution: tuple, points, pad, sigma=10):
    """
    Create a heatmap of the given image, points at the desired resolution.
    """
    points = points - [np.min(points[:, 0]), np.min(points[:1])] + [pad, pad]
    points = (512 * points * [1 / image.shape[1], 1 / image.shape[0]]).astype(int)
    resize = util.resize_image(image, resolution).astype(np.float32)
    heatmap = util.create_ground_truth(resize, points, sigma=sigma)
    
    return util.normalize_image(heatmap, 255)


def crop_to_extreme_points(image: np.ndarray, points, pad=0, zero_pad=False):
    """
    Crop the input image to the bounding box generated by the user input extreme points.
    """
    bbox = util.create_bounding_box(image, points=points, pad=pad, zero_pad=zero_pad)
    crop = util.crop_bounding_box(image, bounding_box=bbox, zero_pad=True)

    return crop


def convert_to_tensor(image: np.ndarray, heatmap: np.ndarray, resolution: tuple):
    """
    Convert the crop and heatmap to PyTorch tensors at the given resolution.
    """
    resize = util.resize_image(image, resolution)
    input = np.concatenate((resize, heatmap[:, :, np.newaxis]), axis=2)

    return torch.from_numpy(input.transpose((2, 0, 1))[np.newaxis, ...])


def collect_extreme_points(points=4, timeout=0):
    """
    Collect the extreme points from an open
    pyplot window and return origins.
    :param points: Number of points to collect (int)
    :param timeout: Set timeout (int)
    """
    extreme_points = np.array(plt.ginput(points,timeout=timeout)).astype(np.int)

    return extreme_points


def detection_to_binary(image: np.ndarray, prediction, points, pad: int, zero_pad: bool, thres=0.8):
    """
    Convert detections (predictions) into binary numpy arrays.
    """
    bbox = util.create_bounding_box(image, points, pad, zero_pad)

    return util.crop_to_binary(prediction, bbox, im_size=image.shape[:2], zero_pad=True, relax=pad) > thres

